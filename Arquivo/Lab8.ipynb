{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aB1fBLWKs2aR",
   "metadata": {
    "id": "aB1fBLWKs2aR"
   },
   "source": [
    "<!-- Projeto-->\n",
    "# <font color='blue'>Projeto</font>\n",
    "## <font color='blue'>Armazenamento e Gestão de Dados com Data Lake e Data Lakehouse</font>\n",
    "## <font color='blue'>Lab 8</font>\n",
    "### <font color='blue'>RAG Pipeline Para IA Generativa no Databricks (com Acesso Pelo Google Colab)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60kA2ElBJkj-",
   "metadata": {
    "id": "60kA2ElBJkj-"
   },
   "source": [
    "## Instalando e Carregando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nAwm_pgONze3",
   "metadata": {
    "id": "nAwm_pgONze3"
   },
   "outputs": [],
   "source": [
    "!pip install -q watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oVSXZRZX-sUy",
   "metadata": {
    "id": "oVSXZRZX-sUy"
   },
   "outputs": [],
   "source": [
    "!pip install -q databricks-cli databricks-sql-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9xNOoFrnscOu",
   "metadata": {
    "id": "9xNOoFrnscOu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acesso negado: 'C:\\\\Users\\\\inha_\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\_win32sysloader.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -q databricks-langchain langchain_milvus langchain-huggingface sentence-transformers beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QvtnFejpO4Z1",
   "metadata": {
    "id": "QvtnFejpO4Z1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"LangChain (Google Colab)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c3ddb-42eb-4884-9c3d-a50db5d37f88",
   "metadata": {
    "id": "292c3ddb-42eb-4884-9c3d-a50db5d37f88"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import bs4\n",
    "import sentence_transformers\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_milvus import Milvus\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eEyHbBCRJmWZ",
   "metadata": {
    "id": "eEyHbBCRJmWZ"
   },
   "source": [
    "## Configurando Credenciais de Acesso ao Databricks\n",
    "\n",
    "Crie o token conforme mostrado nas aulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mj50pCpB_nIh",
   "metadata": {
    "id": "mj50pCpB_nIh"
   },
   "outputs": [],
   "source": [
    "# Defina as credenciais do Databricks\n",
    "os.environ[\"DATABRICKS_HOST\"] = \"url_Databricks\"   # Substitua pela URL do seu Databricks\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"token\"           # Substitua pelo token gerado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "huqjQBHDs5E5",
   "metadata": {
    "id": "huqjQBHDs5E5"
   },
   "source": [
    "## Extraindo Dados da Web e Criando os Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NgcA0sJ_J2jy",
   "metadata": {
    "id": "NgcA0sJ_J2jy"
   },
   "outputs": [],
   "source": [
    "# Cria o carregador de dados da web\n",
    "dsa_loader = WebBaseLoader(\"https://blog.dsacademy.com.br/microsoft-fabric-transformando-dados-em-conhecimento/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ONNSlF3OJ2nQ",
   "metadata": {
    "id": "ONNSlF3OJ2nQ"
   },
   "outputs": [],
   "source": [
    "# Executa o carregador e extrai os dados da web\n",
    "documentos = dsa_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0qKv9ffhJ2pu",
   "metadata": {
    "id": "0qKv9ffhJ2pu"
   },
   "outputs": [],
   "source": [
    "# Cria o separador de texto\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1800, chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zgQo6AG7J2tF",
   "metadata": {
    "id": "zgQo6AG7J2tF"
   },
   "outputs": [],
   "source": [
    "# Aplica o separador e cria os chunks (documentos)\n",
    "docs = text_splitter.split_documents(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SK19Od9EKbgR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SK19Od9EKbgR",
    "outputId": "2d54c2a5-cb20-4b60-9f29-fe557b34522b"
   },
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tVK_Y9O7tXof",
   "metadata": {
    "id": "tVK_Y9O7tXof"
   },
   "source": [
    "## Carregando o Modelo de Embeddings\n",
    "\n",
    "Leia sobre modelos de embeddings no Capítulo 17 do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YXwDl_OwArQP",
   "metadata": {
    "id": "YXwDl_OwArQP"
   },
   "source": [
    "https://huggingface.co/BAAI/bge-small-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29119bbd-2208-4ede-aa0f-ffe06d4a7924",
   "metadata": {
    "id": "29119bbd-2208-4ede-aa0f-ffe06d4a7924"
   },
   "outputs": [],
   "source": [
    "# Carrega o modelo de embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QXTSts3xtcVu",
   "metadata": {
    "id": "QXTSts3xtcVu"
   },
   "source": [
    "## Criando e Carregando o Banco de Dados Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4c33c-3464-4e06-8432-ad300e2ccf4e",
   "metadata": {
    "id": "bab4c33c-3464-4e06-8432-ad300e2ccf4e"
   },
   "outputs": [],
   "source": [
    "# Cria o banco de dados vetorial\n",
    "dsa_vector_db = Milvus.from_documents(documents = docs,\n",
    "                                      embedding = embeddings,\n",
    "                                      collection_name = 'dsa_collection',\n",
    "                                      index_params = {\"index_type\": \"FLAT\"},\n",
    "                                      connection_args = {\"uri\": \"./milvus_dsa.db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_YBbXMqr-efi",
   "metadata": {
    "id": "_YBbXMqr-efi"
   },
   "outputs": [],
   "source": [
    "# Cria o retriever para recuperar os dados do Vector DB\n",
    "retriever = dsa_vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BOeT7N1w-hy6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOeT7N1w-hy6",
    "outputId": "d29f3849-cd5e-4efa-a5e1-d861b3109db3"
   },
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea9137-b0c8-40e8-9da0-1ab33c640f4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62ea9137-b0c8-40e8-9da0-1ab33c640f4e",
    "outputId": "415ffbd2-2b01-4c82-bf23-9c6ea07b25b8"
   },
   "outputs": [],
   "source": [
    "# Testando o Retriever\n",
    "\n",
    "# Define uma frase\n",
    "query = \"O Que é o Microsoft Fabric?\"\n",
    "\n",
    "# Busca texto similar a frase dentro do banco vetorial\n",
    "dsa_vector_db.similarity_search(query, k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rAuhTqKwtuM7",
   "metadata": {
    "id": "rAuhTqKwtuM7"
   },
   "source": [
    "## Definindo o Endpoint do LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1PDyGOjmBKFe",
   "metadata": {
    "id": "1PDyGOjmBKFe"
   },
   "outputs": [],
   "source": [
    "# Definimos aqui o endpoint para o LLM no Databricks\n",
    "llm = ChatDatabricks(endpoint = \"databricks-dbrx-instruct\", max_tokens = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1KCYzSUQLZJT",
   "metadata": {
    "id": "1KCYzSUQLZJT"
   },
   "source": [
    "## Definindo o Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e62ee-1e84-49a5-b70f-d28834b0fa4a",
   "metadata": {
    "id": "459e62ee-1e84-49a5-b70f-d28834b0fa4a"
   },
   "outputs": [],
   "source": [
    "# Cria o texto do prompt\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "        Humano: Você é um assistente de IA e fornece respostas a perguntas do usuário.\n",
    "\n",
    "        Use as seguintes informações para fornecer uma resposta concisa à pergunta entre as tags <question>.\n",
    "        Se você não sabe a resposta, apenas diga que não sabe, não tente inventar uma resposta.\n",
    "\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "\n",
    "        <question>\n",
    "        {question}\n",
    "        </question>\n",
    "\n",
    "        A resposta deve ser específica e usar apenas informações confiáveis.\n",
    "\n",
    "        Assistente:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TiUxDx25BNf1",
   "metadata": {
    "id": "TiUxDx25BNf1"
   },
   "outputs": [],
   "source": [
    "# Cria o prompt template\n",
    "prompt = PromptTemplate(template = PROMPT_TEMPLATE, input_variables = [\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llTZaHFeBNjW",
   "metadata": {
    "id": "llTZaHFeBNjW"
   },
   "outputs": [],
   "source": [
    "# Cria o retriever\n",
    "retriever = dsa_vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gebRf7nwBRyx",
   "metadata": {
    "id": "gebRf7nwBRyx"
   },
   "outputs": [],
   "source": [
    "# Função para formatar os dados\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BrkqlJokLj6x",
   "metadata": {
    "id": "BrkqlJokLj6x"
   },
   "source": [
    "## Definindo o RAG Chain Para o RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a58408-0a5b-4d44-b017-e7ca38eb80a1",
   "metadata": {
    "id": "78a58408-0a5b-4d44-b017-e7ca38eb80a1"
   },
   "outputs": [],
   "source": [
    "# RAG Chain\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Muwrz5CbCW30",
   "metadata": {
    "id": "Muwrz5CbCW30"
   },
   "source": [
    "O RunnablePassthrough no LangChain é uma classe que simplesmente passa os dados de entrada para a saída sem realizar nenhuma modificação ou processamento. É basicamente um \"canal direto\" para os dados. Isso é o que faremos com a questão do usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_LzCxg-vMD2C",
   "metadata": {
    "id": "_LzCxg-vMD2C"
   },
   "source": [
    "## Executando o Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orC8cS8NBSzB",
   "metadata": {
    "id": "orC8cS8NBSzB"
   },
   "outputs": [],
   "source": [
    "# Invoca a chain\n",
    "resposta = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oqg_O29cBS2P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Oqg_O29cBS2P",
    "outputId": "8a432b7f-38ef-41be-97a5-39f7d29d7f55"
   },
   "outputs": [],
   "source": [
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xYaOKXFBMLU7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "xYaOKXFBMLU7",
    "outputId": "64c9e31c-315d-452b-ef71-30311fffc6cd"
   },
   "outputs": [],
   "source": [
    "# Nova questão\n",
    "question = \"Como Empresas Podem Utilizar o Microsoft Fabric?\"\n",
    "resposta = rag_chain.invoke(question)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hBz_yrr6NnOu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "hBz_yrr6NnOu",
    "outputId": "dc4029a8-7372-43c7-a5ab-aa84c78c3056"
   },
   "outputs": [],
   "source": [
    "# Nova questão\n",
    "question = \"Qual o Papel do Cientista de Dados no Microsoft Fabric?\"\n",
    "resposta = rag_chain.invoke(question)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5BQqlPo3NwrU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BQqlPo3NwrU",
    "outputId": "055febcf-d108-48bb-fe33-4488aa4895d2"
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-cAy8rc0Nwuo",
   "metadata": {
    "id": "-cAy8rc0Nwuo"
   },
   "outputs": [],
   "source": [
    "#%watermark -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCmPnrlhNwyl",
   "metadata": {
    "id": "cCmPnrlhNwyl"
   },
   "outputs": [],
   "source": [
    "#%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j8AinquoBVfO",
   "metadata": {
    "id": "j8AinquoBVfO"
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
